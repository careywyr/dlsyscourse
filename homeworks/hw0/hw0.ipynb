{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/careywyr/dlsyscourse/blob/main/homeworks/hw0/hw0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZpZukPzhdly"
      },
      "source": [
        "## 10-714: 作业 0\n",
        "\n",
        "本次作业旨在让你快速了解一些在参加本课程之前应掌握的概念和思路。你需要实现一个基础的 softmax 回归算法，以及一个简单的两层神经网络。你将分别使用原生 Python（基于 numpy 库）和原生 C/C++ 实现这些算法（针对 softmax 回归）。此外，作业还将指导你如何将代码提交到自动评分系统。在这个过程中，我们会提供一些如何实现不同函数的建议，但具体细节由你决定。不过需要提醒的是，在 Python 实现中，应尽量使用 numpy 的线性代数函数，避免使用显式循环，因为显式循环通常会导致代码运行速度大幅降低。\n",
        "\n",
        "**我们清楚，本次作业，特别是开头部分，包含较多的文本内容，代码量相对较少。尽管如此，请务必仔细阅读所有内容。理解作业的流程和设计理念将对你后续完成作业至关重要。**\n",
        "\n",
        "10-714 的所有作业都可以在 Google Colab 环境中完成。不过，与通常直接在 Colab 笔记本中编写代码的方式不同，你的主要代码编写工作将通过下载到 Google Drive 的 `.py` 文件来进行。你主要使用 Colab 笔记本运行 shell 脚本来测试和提交代码至自动评分系统（当然，你也可以在笔记本中测试部分代码片段，但这并不是必须的）。我们选择这种方法的原因是：除了提供一个云端笔记本环境外，Colab 还能够快速启动云端 GPU 系统，这使得你在后期无需物理 GPU 或手动配置 CUDA 库的情况下开发基于 CUDA 的代码。不过，**你可以选择任何你喜欢的开发和提交环境**，但我们无法保证对 Colab 之外的环境提供支持。\n",
        "\n",
        "要开始作业，**请先复制此笔记本文件**，通过“文件”菜单中的“保存到云端硬盘”选项，然后运行下面的代码块。这将把你的 Google Drive 文件夹加载到 Colab 笔记本环境中，创建 `/10714/hw0` 目录，并将 HW0 的公共仓库克隆到该目录。\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-19T13:12:28.735722Z",
          "start_time": "2024-09-19T13:12:28.713235Z"
        },
        "id": "EKpmm00Ahdl0",
        "outputId": "cf347dd0-ae05-4f8b-f5c1-95b289a80ef8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/10714/dlsyscourse/homeworks/hw0\n"
          ]
        }
      ],
      "execution_count": 1,
      "source": [
        "# Code to set up the assignment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# %cd /content/drive/MyDrive/\n",
        "# !mkdir -p 10714\n",
        "# %cd /content/drive/MyDrive/10714\n",
        "# !git clone https://github.com/careywyr/dlsyscourse.git\n",
        "%cd /content/drive/MyDrive/10714/dlsyscourse/homeworks/hw0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLexoNs1hdl1"
      },
      "source": [
        "This next cell will then install the libraries required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-19T13:28:43.674466Z",
          "start_time": "2024-09-19T13:28:40.517452Z"
        },
        "id": "yIw_1hzWhdl2",
        "outputId": "192a09ba-570d-4d66-f326-7e2ac8bd2f7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip3 install pybind11\n",
        "!pip3 install numdifftools"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pybind11\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-2.13.6\n",
            "Collecting numdifftools\n",
            "  Downloading numdifftools-0.9.41-py2.py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.10/dist-packages (from numdifftools) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.8 in /usr/local/lib/python3.10/dist-packages (from numdifftools) (1.13.1)\n",
            "Downloading numdifftools-0.9.41-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.2/100.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numdifftools\n",
            "Successfully installed numdifftools-0.9.41\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-VtrNFkhdl2"
      },
      "source": [
        "## 问题 1: 基础 `add` 函数与测试/自动评分基础\n",
        "\n",
        "为了演示作业流程和自动评分系统的使用，我们将通过实现一个简单的 `add` 函数来说明。请注意，前面运行的命令将在你的 `10714/hw0` 目录中创建如下文件结构：\n",
        "\n",
        "\n",
        "    data/\n",
        "        train-images-idx3-ubyte.gz\n",
        "        train-labels-idx1-ubyte.gz\n",
        "        t10k-images-idx3-ubyte.gz\n",
        "        t10k-labels-idx1-ubyte.gz\n",
        "    src/\n",
        "        simple_ml.py\n",
        "        simple_ml_ext.cpp\n",
        "    tests/\n",
        "        test_simple_ml.py\n",
        "    Makefile\n",
        "    \n",
        "`data/` 目录包含本次作业所需的 MNIST 数据集；`src/` 目录存放需要你编写的源代码文件；`tests/` 目录包含测试文件，便于在本地评估你的解决方案，并提交代码进行自动评分。同时，`Makefile` 文件是用于编译代码的 makefile（特别是与作业中的 C++ 部分相关）。\n",
        "\n",
        "第一道作业题要求你实现 `simple_ml.add()` 函数（该函数本身不用于作业其他部分，目的是帮助你熟悉作业结构）。查看 `src/simple_ml.py` 文件，你将看到如下的 `add()` 函数框架：\n",
        "\n",
        "\n",
        "```python\n",
        "def add(x, y):\n",
        "    \"\"\" A trivial 'add' function you should implement to get used to the\n",
        "    autograder and submission system.  The solution to this problem is in\n",
        "    the homework notebook.\n",
        "\n",
        "    Args:\n",
        "        x (Python number or numpy array)\n",
        "        y (Python number or numpy array)\n",
        "\n",
        "    Return:\n",
        "        Sum of x + y\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE\n",
        "    pass\n",
        "    ### END YOUR CODE\n",
        "```\n",
        "\n",
        "每个函数的文档字符串描述了输入和输出的预期形式（请仔细阅读，这是提交中错误的主要来源之一）。该函数的实现应该比较直观：你只需将 pass 语句替换为正确的实现代码，具体如下：\n",
        "\n",
        "\n",
        "```python\n",
        "def add(x, y):\n",
        "    \"\"\" A trivial 'add' function you should implement to get used to the\n",
        "    autograder and submission system.  The solution to this problem is in the\n",
        "    the homework notebook.\n",
        "\n",
        "    Args:\n",
        "        x (Python number or numpy array)\n",
        "        y (Python number or numpy array)\n",
        "\n",
        "    Return:\n",
        "        Sum of x + y\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE\n",
        "    return x + y\n",
        "    ### END YOUR CODE\n",
        "```\n",
        "现在，请在你的 src/simple_ml.py 文件中完成该函数的实现。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdzUgUr5hdl3"
      },
      "source": [
        "### 运行本地测试\n",
        "\n",
        "接下来，你需要验证代码的正确性，并提交到自动评分系统。在本课程中，我们使用 `pytest` 系统这一标准的单元测试工具。完成 `src/simple_ml.py` 文件中的正确代码后，运行下方的命令来进行测试。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-19T13:36:30.312216Z",
          "start_time": "2024-09-19T13:36:29.172117Z"
        },
        "id": "ScfAR6iYhdl3",
        "outputId": "c241ebd0-0009-47c4-ee93-6c2b39f81def",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python3 -m pytest -k \"add\""
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.4, pluggy-1.5.0\n",
            "rootdir: /content/drive/MyDrive/10714/dlsyscourse/homeworks/hw0\n",
            "plugins: typeguard-4.3.0, anyio-3.7.1\n",
            "collected 6 items / 5 deselected / 1 selected                                                      \u001b[0m\n",
            "\n",
            "tests/test_simple_ml.py \u001b[32m.\u001b[0m\u001b[32m                                                                    [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m================================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m5 deselected\u001b[0m\u001b[32m in 0.40s\u001b[0m\u001b[32m ==================================\u001b[0m\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRsL67jWhdl3"
      },
      "source": [
        "如果一切顺利，你将看到一个测试用例通过。要了解该测试的工作原理，请查看 `tests/test_simple_ml.py` 文件，特别是其中的 `test_add()` 函数：\n",
        "\n",
        "```python\n",
        "def test_add():\n",
        "    assert add(5,6) == 11\n",
        "    assert add(3.2,1.0) == 4.2\n",
        "    assert type(add(4., 4)) == float\n",
        "    np.testing.assert_allclose(add(np.array([1,2]), np.array([3,4])),\n",
        "                               np.array([4,6]))\n",
        "```\n",
        "\n",
        "该代码对你实现的函数运行了一组单元测试。如果函数实现正确，以上所有断言应该通过（即代码将顺利执行且无错误）。但如果你实现有误（例如将 x + y 错误地实现为 x - y），这些断言将会失败，pytest 将指示相应的测试用例未通过。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-19T13:36:37.293709Z",
          "start_time": "2024-09-19T13:36:36.559361Z"
        },
        "id": "ztOpKD_Ohdl3",
        "outputId": "6f3a77e9-360e-4f74-980f-5cc169a62666",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# in this example cell, we replaced \"x + y\" with \"x - y\" in simple_ml.add()\n",
        "!python3 -m pytest -k \"add\""
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.4, pluggy-1.5.0\n",
            "rootdir: /content/drive/MyDrive/10714/dlsyscourse/homeworks/hw0\n",
            "plugins: anyio-3.7.1, typeguard-4.3.0\n",
            "collected 6 items / 5 deselected / 1 selected                                                      \u001b[0m\n",
            "\n",
            "tests/test_simple_ml.py \u001b[32m.\u001b[0m\u001b[32m                                                                    [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m================================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m5 deselected\u001b[0m\u001b[32m in 0.37s\u001b[0m\u001b[32m ==================================\u001b[0m\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHep0HWOhdl4"
      },
      "source": [
        "正如你所见，当断言失败时，会有错误提示指出失败的具体行号，你可以根据提示回去调试代码。**你应当习惯通过分析测试文件来更好地理解你的代码实现应如何工作。**\n",
        "\n",
        "学习如何正确开发和使用单元测试是现代软件开发的核心技能之一。我们希望通过这门课程，你能够熟悉软件开发中单元测试的典型用法。当然，你不必**编写**自己的测试也能通过作业中的问题，但你**应该**熟悉如何阅读我们提供的测试文件，从而理解你的函数应具备的功能。尽管如此，我们仍然**极力建议**你为自己的实现编写额外的测试，特别是在你发现本地测试通过但提交时失败的情况下。\n",
        "\n",
        "最后提醒一点。如果你习惯通过打印语句调试代码，请注意，**pytest 默认会捕获所有输出**。你可以通过为 pytest 添加 `-s` 参数来禁用这一行为，从而显示所有输出。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIs2masrhdl4"
      },
      "source": [
        "## 问题 2: 加载 MNIST 数据\n",
        "\n",
        "现在你已经熟悉了自动评分系统，接下来需要实现 `src/simple_ml.py` 文件中的 `parse_mnist_data()` 函数。以下是该函数的声明（我们通常不会再重复介绍整个过程，但这里再说明一次）。\n",
        "\n",
        "\n",
        "```python\n",
        "def parse_mnist(image_filename, label_filename):\n",
        "    \"\"\" Read an images and labels file in MNIST format.  See this page:\n",
        "    http://yann.lecun.com/exdb/mnist/ for a description of the file format.\n",
        "\n",
        "    Args:\n",
        "        image_filename (str): name of gzipped images file in MNIST format\n",
        "        label_filename (str): name of gzipped labels file in MNIST format\n",
        "\n",
        "    Returns:\n",
        "        Tuple (X,y):\n",
        "            X (numpy.ndarray[np.float32]): 2D numpy array containing the loaded\n",
        "                data.  The dimensionality of the data should be\n",
        "                (num_examples x input_dim) where 'input_dim' is the full\n",
        "                dimension of the data, e.g., since MNIST images are 28x28, it\n",
        "                will be 784.  Values should be of type np.float32, and the data\n",
        "                should be normalized to have a minimum value of 0.0 and a\n",
        "                maximum value of 1.0 (i.e., scale original values of 0 to 0.0\n",
        "                and 255 to 1.0).\n",
        "\n",
        "            y (numpy.ndarray[dtype=np.uint8]): 1D numpy array containing the\n",
        "                labels of the examples.  Values should be of type np.uint8 and\n",
        "                for MNIST will contain the values 0-9.\n",
        "    \"\"\"\n",
        "    ### BEGIN YOUR CODE\n",
        "    pass\n",
        "    ### END YOUR CODE\n",
        "```\n",
        "\n",
        "\n",
        "希望你现在已经熟悉了如何根据文档字符串来理解函数要求，并有了实现该函数的初步思路。首先，访问 http://yann.lecun.com/exdb/mnist/ 或这个[链接](https://web.archive.org/web/20220509025752/http://yann.lecun.com/exdb/mnist/) （页面底部），了解 MNIST 数据文件的二进制格式。接下来，编写一个加载器，读取这些文件并按照文档字符串中的要求返回 numpy 数组（如果实现过程中遇到困难，建议详细参考文档字符串的说明）。我们推荐使用 Python 的 struct 模块（以及 gzip 模块，当然还有 numpy）来实现该函数。\n",
        "\n",
        "实现该函数后，运行本地单元测试来检查代码的正确性。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0CroftmPhdl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b02f3d78-58d3-44c8-ecea-f39ad0e70711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.4, pluggy-1.5.0\n",
            "rootdir: /content/drive/MyDrive/10714/dlsyscourse/homeworks/hw0\n",
            "plugins: typeguard-4.3.0, anyio-3.7.1\n",
            "collected 6 items / 5 deselected / 1 selected                                                      \u001b[0m\n",
            "\n",
            "tests/test_simple_ml.py \u001b[32m.\u001b[0m\u001b[32m                                                                    [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m================================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m5 deselected\u001b[0m\u001b[32m in 1.58s\u001b[0m\u001b[32m ==================================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -k \"parse_mnist\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6o_2Nl_hdl5"
      },
      "source": [
        "## 问题 3: Softmax 损失\n",
        "\n",
        "请实现 `src/simple_ml.py` 中定义的 softmax 损失函数 `softmax_loss()`（也称为交叉熵损失）。回顾一下（我们将在 9 月 1 日的课堂中进一步讨论），对于一个多分类输出 $y \\in \\{1,\\ldots,k\\}$，softmax 损失的输入为 logits 向量 $z \\in \\mathbb{R}^k$ 和真实类别 $y \\in \\{1,\\ldots,k\\}$，其损失函数定义如下：\n",
        "\\begin{equation}\n",
        "\\ell_{\\mathrm{softmax}}(z, y) = \\log\\sum_{i=1}^k \\exp z_i - z_y.\n",
        "\\end{equation}\n",
        "\n",
        "请注意，`softmax_loss()` 函数的输入是一个 logits 的二维数组（即，批次中每个样本的 $k$ 维 logits），以及一个对应的真实标签的一维数组，输出应为整个批次的**平均** softmax 损失。要正确实现这一点，你应避免使用循环，所有计算应通过 numpy 向量化操作实现（作为参考，我们的参考实现仅用一行代码完成）。\n",
        "\n",
        "需要注意的是，在“实际”实现 softmax 损失时，你可能需要对 logits 进行缩放以防止数值溢出，但在此作业中无需考虑这个问题（即使不处理该问题，作业的其余部分仍能正常运行）。以下代码用于运行测试用例。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "O760ZvXchdl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df50a5f6-a8eb-410b-8a7d-0ba8197ff9f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.4, pluggy-1.5.0\n",
            "rootdir: /content/drive/MyDrive/10714/dlsyscourse/homeworks/hw0\n",
            "plugins: typeguard-4.3.0, anyio-3.7.1\n",
            "collected 6 items / 5 deselected / 1 selected                                                      \u001b[0m\n",
            "\n",
            "tests/test_simple_ml.py \u001b[32m.\u001b[0m\u001b[32m                                                                    [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m================================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m5 deselected\u001b[0m\u001b[32m in 0.86s\u001b[0m\u001b[32m ==================================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -k \"softmax_loss\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQAxl2_vhdl5"
      },
      "source": [
        "## 问题 4: softmax 回归的随机梯度下降\n",
        "\n",
        "在本题中，你将实现用于线性 softmax 回归的随机梯度下降 (SGD)。换句话说，正如我们在 9 月 1 日的课程中讨论的那样，我们考虑一个假设，将 $n$ 维输入通过以下函数映射为 $k$ 维的 logits：\n",
        "\\begin{equation}\n",
        "h(x) = \\Theta^T x\n",
        "\\end{equation}\n",
        "其中 $x \\in \\mathbb{R}^n$ 表示输入，$\\Theta \\in \\mathbb{R}^{n \\times k}$ 是模型参数。给定数据集 $\\{(x^{(i)} \\in \\mathbb{R}^n, y^{(i)} \\in \\{1,\\ldots,k\\})\\}$，对于 $i=1,\\ldots,m$，softmax 回归的优化问题表示为：\n",
        "\\begin{equation}\n",
        "\\DeclareMathOperator*{\\minimize}{minimize}\n",
        "\\minimize_{\\Theta} \\; \\frac{1}{m} \\sum_{i=1}^m \\ell_{\\mathrm{softmax}}(\\Theta^T x^{(i)}, y^{(i)}).\n",
        "\\end{equation}\n",
        "\n",
        "回忆课程中介绍的内容，线性 softmax 目标函数的梯度为：\n",
        "\\begin{equation}\n",
        "\\nabla_\\Theta \\ell_{\\mathrm{softmax}}(\\Theta^T x, y) = x (z - e_y)^T\n",
        "\\end{equation}\n",
        "其中\n",
        "\\begin{equation}\n",
        "\\DeclareMathOperator*{\\normalize}{normalize}\n",
        "z = \\frac{\\exp(\\Theta^T x)}{1^T \\exp(\\Theta^T x)} \\equiv \\normalize(\\exp(\\Theta^T x))\n",
        "\\end{equation}\n",
        "即 $z$ 是归一化后的 softmax 概率，$e_y$ 表示第 $y$ 个单位基向量，它是一个除第 $y$ 个位置为 1 之外其余元素均为 0 的向量。\n",
        "\n",
        "我们还可以采用更简洁的表示方式。假设 $X \\in \\mathbb{R}^{m \\times n}$ 表示 $m$ 个输入的设计矩阵（可以是整个数据集或一个小批量），$y \\in \\{1,\\ldots,k\\}^m$ 表示对应的标签向量，扩展后的 $\\ell_{\\mathrm{softmax}}$ 表示平均 softmax 损失，那么\n",
        "\\begin{equation}\n",
        "\\nabla_\\Theta \\ell_{\\mathrm{softmax}}(X \\Theta, y) = \\frac{1}{m} X^T (Z - I_y)\n",
        "\\end{equation}\n",
        "其中\n",
        "\\begin{equation}\n",
        "Z = \\normalize(\\exp(X \\Theta)) \\quad \\mbox{（逐行归一化）}\n",
        "\\end{equation}\n",
        "表示 logits 矩阵，$I_y \\in \\mathbb{R}^{m \\times k}$ 表示标签 $y$ 的独热编码矩阵。\n",
        "\n",
        "基于上述梯度公式，编写 `softmax_regression_epoch()` 函数，该函数在 SGD 的单次迭代中运行，使用指定的学习率/步长 `lr` 和小批量大小 `batch`。按照文档说明，你的函数应当在原地修改 `Theta` 数组。完成实现后，进行测试。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "N0QWmjLThdl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "318ade0c-2d40-4b3a-91b9-0383413f6e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.4, pluggy-1.5.0\n",
            "rootdir: /content/drive/MyDrive/10714/dlsyscourse/homeworks/hw0\n",
            "plugins: typeguard-4.3.0, anyio-3.7.1\n",
            "collected 6 items / 5 deselected / 1 selected                                                      \u001b[0m\n",
            "\n",
            "tests/test_simple_ml.py \u001b[32m.\u001b[0m\u001b[32m                                                                    [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m================================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m5 deselected\u001b[0m\u001b[32m in 0.82s\u001b[0m\u001b[32m ==================================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -k \"softmax_regression_epoch and not cpp\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BE7olRhhdl6"
      },
      "source": [
        "### 使用 softmax 回归训练 MNIST\n",
        "\n",
        "虽然这不是测试的一部分，但既然你已经实现了相关代码，你现在可以尝试使用随机梯度下降 (SGD) 来训练一个完整的 MNIST 线性分类器。为此，可以使用 `src/simple_ml.py` 文件中的 `train_softmax()` 函数（该函数已经为你预先实现，虽然不需要你自行编写，但你可以查看其代码以了解其工作原理）。\n",
        "\n",
        "你可以运行以下代码来测试它的效果。作为参考，我们的实现大约在 Colab 上运行 3 秒，并达到了 7.97% 的分类错误率。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EsMaHsqahdl6",
        "outputId": "590a99c1-8ed8-4458-982c-f3337a59da76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Epoch | Train Loss | Train Err | Test Loss | Test Err |\n",
            "|     0 |    0.35134 |   0.10182 |   0.33588 |  0.09400 |\n",
            "|     1 |    0.32142 |   0.09268 |   0.31086 |  0.08730 |\n",
            "|     2 |    0.30802 |   0.08795 |   0.30097 |  0.08550 |\n",
            "|     3 |    0.29987 |   0.08532 |   0.29558 |  0.08370 |\n",
            "|     4 |    0.29415 |   0.08323 |   0.29215 |  0.08230 |\n",
            "|     5 |    0.28981 |   0.08182 |   0.28973 |  0.08090 |\n",
            "|     6 |    0.28633 |   0.08085 |   0.28793 |  0.08080 |\n",
            "|     7 |    0.28345 |   0.07997 |   0.28651 |  0.08040 |\n",
            "|     8 |    0.28100 |   0.07923 |   0.28537 |  0.08010 |\n",
            "|     9 |    0.27887 |   0.07847 |   0.28442 |  0.07970 |\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append(\"src/\")\n",
        "from simple_ml import train_softmax, parse_mnist\n",
        "\n",
        "X_tr, y_tr = parse_mnist(\"data/train-images-idx3-ubyte.gz\",\n",
        "                         \"data/train-labels-idx1-ubyte.gz\")\n",
        "X_te, y_te = parse_mnist(\"data/t10k-images-idx3-ubyte.gz\",\n",
        "                         \"data/t10k-labels-idx1-ubyte.gz\")\n",
        "\n",
        "train_softmax(X_tr, y_tr, X_te, y_te, epochs=10, lr=0.2, batch=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEPkr-dOhdl6"
      },
      "source": [
        "## 问题 5: 用于两层神经网络的随机梯度下降\n",
        "\n",
        "在编写了用于线性分类器的 SGD 后，我们现在来考虑一个简单的两层神经网络。具体来说，给定输入 $x \\in \\mathbb{R}^n$，我们定义一个不含偏置项的两层神经网络，其形式为：\n",
        "\\begin{equation}\n",
        "z = W_2^T \\mathrm{ReLU}(W_1^T x)\n",
        "\\end{equation}\n",
        "其中 $W_1 \\in \\mathbb{R}^{n \\times d}$ 和 $W_2 \\in \\mathbb{R}^{d \\times k}$ 分别表示网络的权重（网络具有 $d$ 维的隐藏层），$z \\in \\mathbb{R}^k$ 表示网络的输出 logits。我们仍然使用 softmax / 交叉熵损失，因此需要解决如下优化问题：\n",
        "\\begin{equation}\n",
        "\\minimize_{W_1, W_2} \\;\\; \\frac{1}{m} \\sum_{i=1}^m \\ell_{\\mathrm{softmax}}(W_2^T \\mathrm{ReLU}(W_1^T x^{(i)}), y^{(i)}).\n",
        "\\end{equation}\n",
        "或者，使用矩阵 $X \\in \\mathbb{R}^{m \\times n}$ 的批量形式，优化问题可改写为：\n",
        "\\begin{equation}\n",
        "\\minimize_{W_1, W_2} \\;\\; \\ell_{\\mathrm{softmax}}(\\mathrm{ReLU}(X W_1) W_2, y)。\n",
        "\\end{equation}\n",
        "\n",
        "利用链式法则，我们可以推导出该网络的反向传播更新公式（我们将在 9 月 8 日的课程中简要介绍这些内容，但为便于实现，这里提供了最终的公式）。具体为：\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "Z_1 \\in \\mathbb{R}^{m \\times d} & = \\mathrm{ReLU}(X W_1) \\\\\n",
        "G_2 \\in \\mathbb{R}^{m \\times k} & = \\normalize(\\exp(Z_1 W_2)) - I_y \\\\\n",
        "G_1 \\in \\mathbb{R}^{m \\times d} & = \\mathrm{1}\\{Z_1 > 0\\} \\circ (G_2 W_2^T)\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "其中，$\\mathrm{1}\\{Z_1 > 0\\}$ 是一个二值矩阵，取值为 0 或 1，取决于 $Z_1$ 的对应项是否大于 0，$\\circ$ 表示逐元素相乘。此时，目标函数的梯度为：\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "\\nabla_{W_1} \\ell_{\\mathrm{softmax}}(\\mathrm{ReLU}(X W_1) W_2, y) & = \\frac{1}{m} X^T G_1  \\\\\n",
        "\\nabla_{W_2} \\ell_{\\mathrm{softmax}}(\\mathrm{ReLU}(X W_1) W_2, y) & = \\frac{1}{m} Z_1^T G_2。  \\\\\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "**注意**：如果这些公式对你来说有些难以理解（特别是在 9 月 8 日的课程之前），不必过于担心。这些公式只是标准的两层 ReLU 网络的反向传播方程：$Z_1$ 表示正向传播，而 $G_2$ 和 $G_1$ 表示反向传播。不过，根据你使用的神经网络符号和损失函数的形式，公式的具体表达可能有所不同。如果你对这些公式和符号有一定的基础，尤其在 9 月 8 日课程后，它们会更加清晰，这样的理解背景已经足够了（毕竟，深度学习系统的一个主要优势就是不必手动推导这些计算）。但如果这些概念对你完全陌生，建议你在参加本课程前先学习相关的机器学习或神经网络课程，或者准备好进行大量的补习工作。\n",
        "\n",
        "现在，使用这些梯度公式，在 `src/simple_ml.py` 文件中编写 `nn_epoch()` 函数。与之前的问题类似，你的实现应该原地修改 `W1` 和 `W2` 数组。函数实现完成后，运行相应的测试。请确保使用矩阵运算来实现函数，这样的实现方式不仅**更快**，效率更高，而且代码量也更少。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IYAm--fYhdl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b93f10c-aa99-4cc2-fc0a-25e4ef032f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.4, pluggy-1.5.0\n",
            "rootdir: /content/drive/MyDrive/10714/dlsyscourse/homeworks/hw0\n",
            "plugins: typeguard-4.3.0, anyio-3.7.1\n",
            "collected 6 items / 5 deselected / 1 selected                                                      \u001b[0m\n",
            "\n",
            "tests/test_simple_ml.py \u001b[32m.\u001b[0m\u001b[32m                                                                    [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m================================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m5 deselected\u001b[0m\u001b[32m in 2.53s\u001b[0m\u001b[32m ==================================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -k \"nn_epoch\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R10h_JRxhdl7"
      },
      "source": [
        "### 训练完整的两层神经网络\n",
        "\n",
        "和之前一样，尽管这并非通过自动评分系统的必要步骤，但使用你实现的神经网络函数训练一个 MNIST 分类器是一个有趣的尝试。类似于 softmax 回归，`simple_ml.py` 文件中提供了 `train_nn()` 函数，你可以通过随机梯度下降 (SGD) 和多轮次训练来训练这个两层神经网络。例如，下面的代码用来训练一个具有 400 个隐藏单元的两层网络。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gu37B1Jahdl7",
        "outputId": "3e69f77e-64c5-492a-f3e4-3fcc1aca58df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Epoch | Train Loss | Train Err | Test Loss | Test Err |\n",
            "|     0 |    0.15324 |   0.04697 |   0.16305 |  0.04920 |\n",
            "|     1 |    0.09854 |   0.02923 |   0.11604 |  0.03660 |\n",
            "|     2 |    0.07429 |   0.02168 |   0.09774 |  0.03160 |\n",
            "|     3 |    0.05947 |   0.01722 |   0.08791 |  0.02920 |\n",
            "|     4 |    0.04858 |   0.01362 |   0.08112 |  0.02620 |\n",
            "|     5 |    0.04048 |   0.01090 |   0.07687 |  0.02430 |\n",
            "|     6 |    0.03463 |   0.00892 |   0.07433 |  0.02330 |\n",
            "|     7 |    0.03024 |   0.00762 |   0.07256 |  0.02310 |\n",
            "|     8 |    0.02648 |   0.00643 |   0.07104 |  0.02210 |\n",
            "|     9 |    0.02362 |   0.00547 |   0.06991 |  0.02160 |\n",
            "|    10 |    0.02092 |   0.00470 |   0.06882 |  0.02170 |\n",
            "|    11 |    0.01891 |   0.00387 |   0.06849 |  0.02130 |\n",
            "|    12 |    0.01707 |   0.00322 |   0.06782 |  0.02120 |\n",
            "|    13 |    0.01554 |   0.00273 |   0.06740 |  0.02120 |\n",
            "|    14 |    0.01412 |   0.00233 |   0.06674 |  0.02090 |\n",
            "|    15 |    0.01301 |   0.00212 |   0.06666 |  0.02030 |\n",
            "|    16 |    0.01185 |   0.00177 |   0.06630 |  0.02030 |\n",
            "|    17 |    0.01094 |   0.00150 |   0.06594 |  0.01990 |\n",
            "|    18 |    0.01006 |   0.00122 |   0.06582 |  0.01990 |\n",
            "|    19 |    0.00919 |   0.00098 |   0.06532 |  0.01950 |\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "# Reload the simple_ml module which has been cached from the earlier experiment\n",
        "import importlib\n",
        "import simple_ml\n",
        "importlib.reload(simple_ml)\n",
        "\n",
        "sys.path.append(\"src/\")\n",
        "from simple_ml import train_nn, parse_mnist\n",
        "\n",
        "X_tr, y_tr = parse_mnist(\"data/train-images-idx3-ubyte.gz\",\n",
        "                         \"data/train-labels-idx1-ubyte.gz\")\n",
        "X_te, y_te = parse_mnist(\"data/t10k-images-idx3-ubyte.gz\",\n",
        "                         \"data/t10k-labels-idx1-ubyte.gz\")\n",
        "train_nn(X_tr, y_tr, X_te, y_te, hidden_dim=400, epochs=20, lr=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um7f1Stzhdl7"
      },
      "source": [
        "在 Colab 上运行我们的实现大约需要 30 秒，如上所示，它在 MNIST 数据集上达到了 1.89% 的误差率。对于不到 20 行的代码来说，这个结果还不错……\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joSNKRkUhdl8"
      },
      "source": [
        "## 问题 6: C++中的Softmax回归\n",
        "\n",
        "这道作业的最后一个问题要求你实现与问题 4 中相同的函数，即运行一个线性 Softmax 回归单次迭代的函数。不同的是，这次你将使用 C++ 实现，而不是 Python。（严格来说，这更像是原生 C 的实现，但我们借助 C++ 功能，通过 [pybind11](https://pybind11.readthedocs.io) 库与 Python 交互。在后续作业中，你也将用这个库来实现 C++ 与 Python 的接口。虽然存在其他替代方案，但 pybind11 库相对较好用，因为它是一个仅包含头文件的库，允许你在一个 C++ 源文件中实现整个 Python/C++ 接口。）\n",
        "\n",
        "你将实现的代码位于 `src/simple_ml_ext.cpp` 文件中。我们先来看这个文件的相关部分。你需要在以下函数中实现你的代码：\n",
        "\n",
        "\n",
        "```cpp\n",
        "void softmax_regression_epoch_cpp(const float *X, const unsigned char *y,\n",
        "\t\t\t\t\t\t\t\t  float *theta, size_t m, size_t n, size_t k,\n",
        "\t\t\t\t\t\t\t\t  float lr, size_t batch)\n",
        "{\n",
        "    /**\n",
        "     * A C++ version of the softmax regression epoch code.  This should run a\n",
        "     * single epoch over the data defined by X and y (and sizes m,n,k), and\n",
        "     * modify theta in place.  Your function will probably want to allocate\n",
        "     * (and then delete) some helper arrays to store the logits and gradients.\n",
        "     *\n",
        "     * Args:\n",
        "     *     X (const float *): pointer to X data, of size m*n, stored in row\n",
        "     *          major (C) format\n",
        "     *     y (const unsigned char *): pointer to y data, of size m\n",
        "     *     theta (float *): pointer to theta data, of size n*k, stored in row\n",
        "     *          major (C) format\n",
        "     *     m (size_t): number of examples\n",
        "     *     n (size_t): input dimension\n",
        "     *     k (size_t): number of classes\n",
        "     *     lr (float): learning rate / SGD step size\n",
        "     *     batch (int): SGD minibatch size\n",
        "     *\n",
        "     * Returns:\n",
        "     *     (None)\n",
        "     */\n",
        "\n",
        "    /// YOUR CODE HERE\n",
        "    \n",
        "    /// END YOUR CODE\n",
        "}\n",
        "```\n",
        "我们进一步分析这个函数的参数。该函数基本上与 Python 实现的功能一致，但由于我们处理的是数组的原始指针，而不是更高级的\"矩阵\"数据结构，因此需要传递一些额外的参数。具体来说，X、y 和 theta 是指向前面部分 numpy 数组原始数据的指针；对于二维数组，它们是按 C 风格（行优先）存储的，即 $X$ 的第一行依次存储在 X 的第一个字节开始，接着是第二行，依次类推（这与列优先的存储方式相反，后者按顺序存储矩阵的每一列）。我们假设数据中没有额外填充字节，也就是说，第二行紧接着第一行开始存储，不会为了对齐内存边界而增加额外字节（这些细节将在后续课程中提到，目前可以忽略）。因为函数只接收原始数据，为了知道矩阵的大小，必须显式传递 m、n 和 k 这些参数。\n",
        "\n",
        "为了演示如何访问数据，注意，由于 X 表示一个行优先的 $m \\times n$ 矩阵，若要访问 $X$ 的第 $(i,j)$ 元素（第 $i$ 行的第 $j$ 列），应使用以下索引：\n",
        "\n",
        "```cpp\n",
        "X[i*n + j]\n",
        "```\n",
        "也就是说，由于 X 有 $n$ 列，并且按行顺序存储，因此我们需要通过 `X[i*n]` 来访问第 $i$ 行；如果想访问该行的第 $j$ 个元素，则可以使用上面的索引。同样的逻辑适用于 theta 矩阵，不过因为 theta 是一个 $n \\times k$ 的矩阵，要访问其第 $(i,j)$ 元素，你需要使用以下索引。\n",
        "\n",
        "```cpp\n",
        "theta[i*k + j]\n",
        "```\n",
        "与 Python 不同，C++ 中直接访问内存时需要非常谨慎，并且要习惯这种索引方式（你也可以构建一些数据结构来简化访问方式，但在本次作业中，你应该坚持使用原始索引）。\n",
        "\n",
        "实现的第二个关键点是 pybind11 代码，它负责提供 Python 接口：\n",
        "```cpp\n",
        "PYBIND11_MODULE(simple_ml_ext, m) {\n",
        "    m.def(\"softmax_regression_epoch_cpp\",\n",
        "    \t[](py::array_t<float, py::array::c_style> X,\n",
        "           py::array_t<unsigned char, py::array::c_style> y,\n",
        "           py::array_t<float, py::array::c_style> theta,\n",
        "           float lr,\n",
        "           int batch) {\n",
        "        softmax_regression_epoch_cpp(\n",
        "        \tstatic_cast<const float*>(X.request().ptr),\n",
        "            static_cast<const unsigned char*>(y.request().ptr),\n",
        "            static_cast<float*>(theta.request().ptr),\n",
        "            X.request().shape[0],\n",
        "            X.request().shape[1],\n",
        "            theta.request().shape[1],\n",
        "            lr,\n",
        "            batch\n",
        "           );\n",
        "    },\n",
        "    py::arg(\"X\"), py::arg(\"y\"), py::arg(\"theta\"),\n",
        "    py::arg(\"lr\"), py::arg(\"batch\"));\n",
        "}\n",
        "```\n",
        "这段代码已经为你提供，无需更改。简单来说，这段代码只是从提供的输入中提取原始指针（通过 pybind 的 numpy 接口），然后调用 softmax_regression_epoch_cpp 函数。\n",
        "\n",
        "在理解了这些背景信息后，你可以开始实现 softmax_regression_epoch_cpp 函数，完成与 Python 实现相同的更新操作。注意，由于你是直接操作原始数据，你需要手动完成所有矩阵与向量的乘法，而不能依赖 numpy 来处理所有矩阵运算（注意：不要使用外部矩阵库如 Eigen，只需自己编写乘法代码……这个实现其实相对简单）。完成后，可以通过以下命令测试你的实现。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "D8BIO7CJhdl8",
        "outputId": "227008c3-ab9a-4c37-a22a-00d74c74112a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c++ -O3 -Wall -shared -std=c++11 -fPIC $(python3 -m pybind11 --includes) src/simple_ml_ext.cpp -o src/simple_ml_ext.so\n",
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.4, pluggy-1.5.0\n",
            "rootdir: /content/drive/MyDrive/10714/dlsyscourse/homeworks/hw0\n",
            "plugins: typeguard-4.3.0, anyio-3.7.1\n",
            "collected 6 items / 5 deselected / 1 selected                                                      \u001b[0m\n",
            "\n",
            "tests/test_simple_ml.py \u001b[32m.\u001b[0m\u001b[32m                                                                    [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m================================= \u001b[32m\u001b[1m1 passed\u001b[0m, \u001b[33m5 deselected\u001b[0m\u001b[32m in 1.03s\u001b[0m\u001b[32m ==================================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!make\n",
        "!python3 -m pytest -k \"softmax_regression_epoch_cpp\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5-YOBPchdl8"
      },
      "source": [
        "需要注意的是，与之前的代码不同，我们必须先编译 C++ 扩展才能进行运行和测试。每当你的代码中包含 C++ 组件时，编译都是必需的。不过在这些情况下，我们会提供 Makefile 文件，它将编译所有相关函数并包含必要的库和头文件。最后，别忘了将结果提交到 mugrade。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqf61zukhdl9"
      },
      "source": [
        "### 使用 C++ 版本训练完整的 Softmax 回归分类器\n",
        "\n",
        "现在我们来尝试使用“直接内存访问”的 C++ 版本训练完整的 Softmax 回归分类器。如果之前的 Python 版本大约需要 3 秒，这次应该会快得多。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kafJm9mshdl9",
        "outputId": "0c28b318-0459-4c10-9507-14c9ab21ce59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Epoch | Train Loss | Train Err | Test Loss | Test Err |\n",
            "|     0 |    0.35134 |   0.10182 |   0.33588 |  0.09400 |\n",
            "|     1 |    0.32142 |   0.09268 |   0.31086 |  0.08730 |\n",
            "|     2 |    0.30802 |   0.08795 |   0.30097 |  0.08550 |\n",
            "|     3 |    0.29987 |   0.08532 |   0.29558 |  0.08370 |\n",
            "|     4 |    0.29415 |   0.08323 |   0.29215 |  0.08230 |\n",
            "|     5 |    0.28981 |   0.08182 |   0.28973 |  0.08090 |\n",
            "|     6 |    0.28633 |   0.08085 |   0.28793 |  0.08080 |\n",
            "|     7 |    0.28345 |   0.07997 |   0.28651 |  0.08040 |\n",
            "|     8 |    0.28100 |   0.07923 |   0.28537 |  0.08010 |\n",
            "|     9 |    0.27887 |   0.07847 |   0.28442 |  0.07970 |\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append(\"src/\")\n",
        "\n",
        "# Reload the simple_ml module to include the newly-compiled C++ extension\n",
        "import importlib\n",
        "import simple_ml\n",
        "importlib.reload(simple_ml)\n",
        "\n",
        "from simple_ml import train_softmax, parse_mnist\n",
        "\n",
        "X_tr, y_tr = parse_mnist(\"data/train-images-idx3-ubyte.gz\",\n",
        "                         \"data/train-labels-idx1-ubyte.gz\")\n",
        "X_te, y_te = parse_mnist(\"data/t10k-images-idx3-ubyte.gz\",\n",
        "                         \"data/t10k-labels-idx1-ubyte.gz\")\n",
        "\n",
        "train_softmax(X_tr, y_tr, X_te, y_te, epochs=10, lr = 0.2, batch=100, cpp=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDFxrLcLhdl9"
      },
      "source": [
        "正如预期的那样，结果与 Python 版本完全一致，但速度却……慢了大约 5 倍？这是为什么呢？原来，你为 C++ 版本编写的“手动”矩阵乘法代码效率非常低。虽然 Python 本身是一个较慢的解释型语言，但 numpy 的底层实际上是用 C（甚至可能是 Fortran）编写的矩阵乘法库，这些库经过高度优化，能够充分利用向量化操作、处理器缓存层次结构等特性，这些都是实现高效数值运算的关键。我们会在后续课程中详细讨论这些优化原理，甚至还会让你编写一个矩阵库，能够在某些特定情况下实现较为高效的运算——但总体上，超越 numpy 的效率并不容易。\n",
        "\n",
        "不过目前，如果你的代码能够成功重现 Python 的行为，那你已经完成了这次作业。接下来，我们将进一步探索自动微分的相关内容。\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}